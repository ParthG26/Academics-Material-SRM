# -*- coding: utf-8 -*-
"""Rl exp10 Q-Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IYC-T7LT_YzMpPctR1ykUtVHupA65bsK
"""

import numpy as np
import gym

# Set the parameters
epsilon = 0.9
total_episodes = 10000
max_steps = 100
alpha = 0.85
gamma = 0.95

# Create the FrozenLake environment
env = gym.make("FrozenLake-v1")

# Initialize the Q-table with zeros
Q = np.zeros([env.observation_space.n, env.action_space.n])

# Implement the Q-learning algorithm
for episode in range(total_episodes):
    state = env.reset()
    done = False
    step = 0

    while not done and step < max_steps:
        if np.random.random() < epsilon:
            action = env.action_space.sample()
        else:
            action = np.argmax(Q[state])

        next_state, reward, done, _ = env.step(action)

        # Q-learning formula
        Q[state, action] = Q[state, action] + alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])

        state = next_state
        step += 1

# Print the final Q-table
print("Final Q-table:")
print(np.round(Q, decimals=3))